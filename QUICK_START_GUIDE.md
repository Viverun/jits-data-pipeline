# Quick Start Guide - Pipeline v2.0.1

**Version:** 2.0.1 (All Critical Fixes Applied)  
**Date:** January 18, 2026  
**Status:** âœ… Production Ready

---

## ğŸš€ Quick Start (3 Steps)

### 1. Clean Previous Data
```bash
# Delete old processed files
python -c "
import shutil
from pathlib import Path

# Clean interim directories
for d in Path('interim').glob('*'):
    if d.is_dir():
        shutil.rmtree(d)
        print(f'Cleaned: {d}')

# Clean output
if Path('legal_ai_toolkit/data/judgments').exists():
    shutil.rmtree('legal_ai_toolkit/data/judgments')
    print('Cleaned: legal_ai_toolkit/data/judgments')

print('âœ… Cleanup complete!')
"
```

### 2. Run Pipeline
```bash
# Full pipeline with all critical fixes
python -m legal_ai_toolkit.cli run-pipeline --workers 4
```

### 3. Validate Results
```bash
# Validate general pipeline
python validate_v2_pipeline.py

# Validate critical fixes (ID timing, file renaming, etc.)
python validate_critical_fixes.py
```

---

## ğŸ“‹ Pipeline Steps (NEW Order)

```
Step 1: Ingestion
  â†“ Generates: TEMP_ABC123DEF456

Step 2: Metadata Extraction
  â†“ Extracts: court, parties, bench
  â†“ Keeps: TEMP_ABC123DEF456

Step 3: Issue Extraction
  â†“ Extracts: legal issues
  â†“ Keeps: TEMP_ABC123DEF456

Step 4: Classification
  â†“ Uses: issues for better accuracy
  â†“ Keeps: TEMP_ABC123DEF456
  â†“ Adds: classification.domain

Step 4.5: ID Regeneration â­ NEW
  â†“ Regenerates: IN-HC-DEL-2023-SV-ABC123
  â†“ Renames files: TEMP_*.json â†’ IN-HC-*.json
  â†“ Tracks: ID history in provenance

Step 5: Statutory Transitions
  â†“ Uses: stable IDs

Step 6: Citation Extraction
  â†“ Uses: case name for self-filtering

Step 7: Similarity Analysis
  â†“ Uses: stable IDs (no orphaned references)

Step 8: Consolidation
  â†“ Final unified JSON
```

---

## âœ… Expected Outputs

### Interim Directories
```
interim/
â”œâ”€â”€ normalized_text/          # Step 1: TEMP_*.json
â”œâ”€â”€ headers_extracted/         # Step 2: TEMP_*.json
â”œâ”€â”€ issues_extracted/          # Step 3: TEMP_*.json
â”œâ”€â”€ classified/                # Step 4: TEMP_*.json
â”œâ”€â”€ id_regenerated/ â­         # Step 4.5: IN-HC-*.json (proper IDs!)
â”œâ”€â”€ transitions_extracted/     # Step 5: IN-HC-*.json
â””â”€â”€ citations_extracted/       # Step 6: IN-HC-*.json
```

### Final Output
```
legal_ai_toolkit/data/judgments/
â”œâ”€â”€ IN-HC-DEL-2023-CV-ABC123.json
â”œâ”€â”€ IN-HC-DEL-2023-SV-DEF456.json
â”œâ”€â”€ IN-SC-SUP-2024-CR-GHI789.json
â””â”€â”€ ...

annotations/similarity/
â”œâ”€â”€ edges.jsonl                # Edges with stable IDs
â”œâ”€â”€ clusters.json
â””â”€â”€ signals/
    â”œâ”€â”€ IN-HC-DEL-2023-CV-ABC123.json
    â””â”€â”€ ...
```

---

## ğŸ” Validation Checklist

### âœ… Step 1: Check ID Format
```bash
# Should see proper IDs, NOT TEMP_
ls interim/id_regenerated/*.json | head -5

# Expected output:
# IN-HC-DEL-2023-CV-ABC123.json
# IN-HC-DEL-2023-SV-DEF456.json
```

### âœ… Step 2: Verify Domain Codes
```bash
python -c "
import json
from pathlib import Path

for f in list(Path('interim/id_regenerated').glob('*.json'))[:5]:
    data = json.load(open(f))
    jid = data['judgment_id']
    domain = data.get('classification', {}).get('domain')
    
    # Check domain code matches
    if domain == 'service' and '-SV-' in jid:
        print(f'âœ… {f.name}: service â†’ SV')
    elif domain == 'criminal' and '-CR-' in jid:
        print(f'âœ… {f.name}: criminal â†’ CR')
    elif domain == 'civil' and '-CV-' in jid:
        print(f'âœ… {f.name}: civil â†’ CV')
    else:
        print(f'âŒ {f.name}: {domain} (code mismatch!)')
"
```

### âœ… Step 3: Check File Renaming
```bash
python -c "
import json
from pathlib import Path

for f in list(Path('interim/id_regenerated').glob('*.json'))[:5]:
    data = json.load(open(f))
    filename = f.stem
    internal_id = data['judgment_id']
    
    if filename == internal_id:
        print(f'âœ… {filename}')
    else:
        print(f'âŒ Mismatch: {filename} vs {internal_id}')
"
```

### âœ… Step 4: Verify Similarity Edges
```bash
# Check edges don't have TEMP_ IDs
grep "TEMP_" annotations/similarity/edges.jsonl

# Expected output: (nothing - no matches)
```

---

## ğŸ› Troubleshooting

### Issue: TEMP_ IDs in id_regenerated/
**Symptom:**
```bash
ls interim/id_regenerated/
# Output: TEMP_ABC123.json  âŒ
```

**Cause:** ID regeneration step didn't run or failed

**Fix:**
```bash
# Run ID regeneration step manually
python -m legal_ai_toolkit.cli run-step id_regen

# Check error log
cat interim/id_regenerated/errors_*.json
```

---

### Issue: Domain code wrong in ID
**Symptom:**
```bash
# Service matter classified as CV instead of SV
IN-HC-DEL-2023-CV-ABC123.json  âŒ
{"classification": {"domain": "service"}}
```

**Cause:** Classification step didn't run before ID regeneration

**Fix:**
```bash
# Re-run in correct order
python -m legal_ai_toolkit.cli run-step issues
python -m legal_ai_toolkit.cli run-step classify
python -m legal_ai_toolkit.cli run-step id_regen
```

---

### Issue: Filename doesn't match internal ID
**Symptom:**
```bash
# File: TEMP_ABC123.json
# Internal: IN-HC-DEL-2023-SV-ABC123
```

**Cause:** File renaming logic not working

**Fix:**
```bash
# Check BaseStep has file renaming code
grep -A 10 "old_id != new_id" legal_ai_toolkit/pipeline/runner.py

# Should see:
# if old_id != new_id:
#     out_path = self.output_dir / f"{new_id}.json"
```

---

### Issue: Orphaned similarity edges
**Symptom:**
```bash
# Edges reference IDs that don't exist
{"from": "TEMP_ABC123", "to": "TEMP_DEF456"}
```

**Cause:** Similarity ran before ID regeneration

**Fix:**
```bash
# Re-run similarity AFTER id_regen
python -m legal_ai_toolkit.cli run-step id_regen
python -m legal_ai_toolkit.cli run-step transitions
python -m legal_ai_toolkit.cli run-step citations
python -m legal_ai_toolkit.cli run-step similarity
```

---

## ğŸ“Š Performance Expectations

### Small Dataset (100 judgments)
- **Ingestion:** ~30 seconds
- **Metadata:** ~1 minute
- **Issues:** ~1 minute
- **Classification:** ~30 seconds
- **ID Regeneration:** ~10 seconds â­
- **Transitions:** ~1 minute
- **Citations:** ~2 minutes
- **Similarity:** ~2 minutes (with optimization)
- **Total:** ~8-10 minutes

### Large Dataset (1000 judgments)
- **Ingestion:** ~5 minutes
- **Metadata:** ~10 minutes
- **Issues:** ~10 minutes
- **Classification:** ~5 minutes
- **ID Regeneration:** ~1 minute â­
- **Transitions:** ~10 minutes
- **Citations:** ~20 minutes
- **Similarity:** ~20 minutes (with optimization, was ~40-60 min)
- **Total:** ~80-90 minutes

---

## ğŸ¯ Success Criteria

Before deploying to production, verify:

- [ ] âœ… No TEMP_ IDs in final output
- [ ] âœ… Domain codes match classification (service â†’ SV, criminal â†’ CR, civil â†’ CV)
- [ ] âœ… Filenames match internal judgment_id
- [ ] âœ… No orphaned references in similarity edges
- [ ] âœ… Provenance tracking includes ID history
- [ ] âœ… Error logs generated for failures
- [ ] âœ… All validation scripts pass

**Run both validation scripts:**
```bash
python validate_v2_pipeline.py       # General validation
python validate_critical_fixes.py    # Critical fixes validation
```

Both should show: **"ALL CHECKS PASSED"** âœ…

---

## ğŸ“ Support

### Quick Commands
```bash
# Run full pipeline
python -m legal_ai_toolkit.cli run-pipeline --workers 4

# Run single step
python -m legal_ai_toolkit.cli run-step <step_name>
# Steps: ingest, metadata, issues, classify, id_regen, transitions, citations, similarity, consolidate

# Validate
python validate_v2_pipeline.py
python validate_critical_fixes.py

# Check errors
find interim/ -name "errors_*.json" -exec cat {} \;
```

### Documentation
- `CODE_REVIEW_IMPLEMENTATION_SUMMARY.md` - Full implementation details
- `MIGRATION_GUIDE_V2.md` - Migration strategies
- `PIPELINE_REFACTORING_SUMMARY.md` - Technical details

---

**Pipeline v2.0.1 - All Critical Fixes Applied** ğŸš€
